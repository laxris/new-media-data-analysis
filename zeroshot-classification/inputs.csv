Let us start off with the year so far, are you waking up every morning energized about what's happening in A.I. or are you yourself losing sleep because of the potential concerns? When we consider what's happened with China GDP T over the last few months, we really do need to take. It's about the hasty miss. The speed before safety. That's really kind of driven the the release of Chuck Beatty into the into the worlds. We know that researchers have easily gotten around the preventative content filters of and beauty to produce a cyber search, security threats such as new strands of polymorphic malware. They've been able to create a fraudulent phishing campaigns and expose dealers. We've also seen the potential for chatgpt, Beatty and other large language models to, in a sense, create fire hoses, disinformation and propaganda that can flood the digital public square with lies and alternative facts. And so right. I would say there there's a lot of exciting things going on, but there's a lot of reason to for us to be concerned with showing on the screen just how rapid the rollout is from research to development to new product launch across a number of names and platforms in the wall today. I know it's been astonishing tracking the headlines of how quickly new products and new names are born. It's that pace dangerous or is that just the reality of innovation? I would I would hesitate to say it's the reality of innovation. I would say that we really do need to avoid what's been going on, which is this kind of shocking irresponsibility of bringing things to the market. With with increasing speed, we've seen the move move fast and break things attitude before. But this attitude is is becoming perhaps more of a concern as the scale of the potential consequences become wider and deeper into society. And I think that we we really need to we need to press the pause button a bit when it comes to the acceleration of the technologies. So I guess that the debate moves to who should police their CEO. When you reflect on the Alan Turing Institute's work around this area, your work in ethics. What's interesting is how many papers have been published by the likes of open A.I. guidelines that the industry themselves have put forward. Should they be the ones to do that? Or is there a need for very quickly a conversation around third party oversight? We absolutely need third party oversight when it comes to these systems, especially these highly impactful systems that will affect large populations. Now, that's not to say that the practices of the innovators in designing, developing and deploying these systems shouldn't involve strong ex ante practices of impact assessment, transparency and accountability of bias mitigation. But these things simply must be subject to the oversight of third party bodies. Now regulators and perhaps certification schemes. David, what is the single biggest ethical consideration around the use of A.I. in the real world today? I mean, if we're if we're thinking about these large language models and foundation models, we have to recognize that what these systems are doing is merely drawing on. Billions of of of parameters that that that come from human behavior, that can have discrimination embedded in it, that can be that can be racist and sexist and can can in fact ultimately be re replicated and amplified in systems. And so we really need to be aware that if we do not approach these these systems with a sufficient bias mitigation mechanisms, we will simply replicates deeper patterns than just. Right. No.
